{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import configparser\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Read configuration file\n",
    "config = configparser.RawConfigParser()\n",
    "config.read('../configs/param.cfg')\n",
    "#print(f'ACCESS_KEY_ID: {config[\"AWS_CREDENTIAL\"][\"AWS_ACCESS_KEY_ID\"]}\\n\\\n",
    "#SECRET_ACCESS_KEY: {config[\"AWS_CREDENTIAL\"][\"AWS_SECRET_ACCESS_KEY\"]}\\n\\\n",
    "#SESSION_TOKEN: {config[\"AWS_CREDENTIAL\"][\"AWS_SESSION_TOKEN\"]}')\n",
    "\n",
    "url_question = config[\"SOURCE_URL\"][\"so_question_zip\"]\n",
    "url_question_tag = config[\"SOURCE_URL\"][\"so_question_tag_zip\"]\n",
    "\n",
    "path_question = '../assets/question.zip'\n",
    "path_question_tag = '../assets/question_tag.zip'\n",
    "\n",
    "req_question = requests.get(url_question, allow_redirects=True)\n",
    "req_question_tag = requests.get(url_question_tag, allow_redirects=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244148972"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(path_question, 'wb').write(req_question.content)\n",
    "open(path_question_tag, 'wb').write(req_question_tag.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Read original files into DataFrame\n",
    "# Read directly from request\n",
    "#df_question = pd.read_csv(io.BytesIO(req_question.content), compression='zip', nrows=1000)\n",
    "#df_question_tag = pd.read_csv(io.BytesIO(req_question_tag.content), compression='zip', nrows=1000)\n",
    "\n",
    "# Read from downloaded files\n",
    "df_question = pd.read_csv(path_question, compression='zip', nrows=1000)\n",
    "df_question_tag = pd.read_csv(path_question_tag, compression='zip', nrows=1000)\n",
    "\n",
    "# Add hash_key column to track data changes in each row\n",
    "df_question['hash_key'] = df_question.apply(lambda row: pd.util.hash_pandas_object(\n",
    "    pd.Series(row.to_string())), axis=1)\n",
    "df_question_tag['hash_key'] = df_question_tag.apply(lambda row: pd.util.hash_pandas_object(\n",
    "    pd.Series(row.to_string())), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create StringIO to read from DataFrame to CSV files\n",
    "csv_buffer = io.StringIO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create AWS Credential Session\n",
    "session = boto3.session.Session(aws_access_key_id=config[\"AWS_CREDENTIAL\"][\"AWS_ACCESS_KEY_ID\"],\n",
    "                                aws_secret_access_key=config[\"AWS_CREDENTIAL\"][\"AWS_SECRET_ACCESS_KEY\"],\n",
    "                                aws_session_token=config[\"AWS_CREDENTIAL\"][\"AWS_SESSION_TOKEN\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '4D4A728SKPYDKWZC',\n",
       "  'HostId': 'amtnlnVQ0qOn5cN/rBYDu//R62CJDhtBAHJ4G8WOOEwy7l4vI56vl36YWoudxyX+F/eCGQ/1TDw=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'amtnlnVQ0qOn5cN/rBYDu//R62CJDhtBAHJ4G8WOOEwy7l4vI56vl36YWoudxyX+F/eCGQ/1TDw=',\n",
       "   'x-amz-request-id': '4D4A728SKPYDKWZC',\n",
       "   'date': 'Sun, 14 Nov 2021 04:49:43 GMT',\n",
       "   'etag': '\"7bc2e5af93302f7c4319d199af4e5052\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0',\n",
       "   'connection': 'close'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"7bc2e5af93302f7c4319d199af4e5052\"'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put objects into S3 datalake\n",
    "# Create resource and object\n",
    "s3 = session.resource('s3')\n",
    "obj_questions = s3.Object('so-question-dl', 'questions.csv')\n",
    "obj_question_tags = s3.Object('so-question-dl', 'question_tags.csv')\n",
    "\n",
    "# Put [questions.csv] object into bucket\n",
    "df_question.to_csv(csv_buffer)\n",
    "obj_questions.put(Body=csv_buffer.getvalue())\n",
    "csv_buffer.truncate(0)\n",
    "\n",
    "# Put [question_tags.csv] object into bucket\n",
    "df_question_tag.to_csv(csv_buffer)\n",
    "obj_question_tags.put(Body=csv_buffer.getvalue())\n",
    "csv_buffer.truncate(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date = df_question[['CreationDate', 'ClosedDate', 'DeletionDate']].apply(lambda date: pd.to_datetime(date).dt.date, axis=1)\n",
    "df_question.drop(labels=['CreationDate', 'ClosedDate', 'DeletionDate'], axis=1, inplace=True)\n",
    "df_question = pd.concat([df_question, df_date], axis=1)\n",
    "sr_date = pd.concat([df_date['CreationDate'], df_date['ClosedDate'], df_date['DeletionDate']], axis=0, ignore_index=True).dropna().drop_duplicates().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_question.drop(labels=['CreationDate', 'ClosedDate', 'DeletionDate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date = pd.DataFrame({'date': sr_date,\n",
    "                        'day': sr_date.apply(lambda d: d.day),\n",
    "                        'weekday': sr_date.apply(lambda d: d.weekday()),\n",
    "                        'month': sr_date.apply(lambda d: d.month),\n",
    "                        'quarter': sr_date.apply(lambda d: int(np.ceil(d.month/3))),\n",
    "                        'year': sr_date.apply(lambda d: d.year)}).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_question['status'] = df_question.apply(lambda row:\n",
    "                                          'Closed' if isinstance(row['ClosedDate'], str) else\n",
    "                                          'Deleted' if isinstance(row['DeletionDate'], str) else\n",
    "                                          'Open', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tag = df_question_tag['Tag'].drop_duplicates().reset_index(drop=True).reset_index()\n",
    "df_tag.rename(columns={'index': 'TagID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>hash_key</th>\n",
       "      <th>TagID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14938764676594239031</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>11186365449698795993</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>10160016385319721572</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>17336394884955031404</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>3162135025239554358</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1988</td>\n",
       "      <td>2298376297963747135</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1988</td>\n",
       "      <td>3143731599844340150</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1995</td>\n",
       "      <td>4333287139566122752</td>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1999</td>\n",
       "      <td>12610558052624434707</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2018</td>\n",
       "      <td>18316756407333684320</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id              hash_key  TagID\n",
       "0       1  14938764676594239031      0\n",
       "1       4  11186365449698795993      1\n",
       "2       8  10160016385319721572      1\n",
       "3       9  17336394884955031404      1\n",
       "4      11   3162135025239554358      1\n",
       "..    ...                   ...    ...\n",
       "995  1988   2298376297963747135    457\n",
       "996  1988   3143731599844340150    458\n",
       "997  1995   4333287139566122752    459\n",
       "998  1999  12610558052624434707    460\n",
       "999  2018  18316756407333684320    461\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_question_tag = df_question_tag.merge(df_tag, on='Tag')\n",
    "df_question_tag.drop('Tag', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_config_file():\n",
    "    \"\"\"\n",
    "    Read configuration file\n",
    "    :return:\n",
    "    RawConfigParser with config data inside\n",
    "    \"\"\"\n",
    "    import configparser\n",
    "    # Read configuration file\n",
    "    config = configparser.RawConfigParser()\n",
    "    config.read('../configs/param.cfg')\n",
    "    # print(f'ACCESS_KEY_ID: {config[\"AWS_CREDENTIAL\"][\"AWS_ACCESS_KEY_ID\"]}\\n\\\n",
    "    # SECRET_ACCESS_KEY: {config[\"AWS_CREDENTIAL\"][\"AWS_SECRET_ACCESS_KEY\"]}\\n\\\n",
    "    # SESSION_TOKEN: {config[\"AWS_CREDENTIAL\"][\"AWS_SESSION_TOKEN\"]}')\n",
    "    return config\n",
    "\n",
    "def download_data(config, data_name):\n",
    "    \"\"\"\n",
    "    Send 1 request to data sources and download [questions] data\n",
    "    :return:\n",
    "    none, save downloaded file into cluster hard disk\n",
    "    \"\"\"\n",
    "    import requests\n",
    "\n",
    "    path_question = config['FILE_LOCATION'][f'loc_so_{data_name}']\n",
    "    url_question = config['SOURCE_URL'][f'so_{data_name}_zip']\n",
    "    req_question = requests.get(url_question, allow_redirects=True)\n",
    "    open(path_question, 'wb').write(req_question.content)\n",
    "\n",
    "def add_hash_column(config, data_name):\n",
    "    \"\"\"\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    path_data = config['FILE_LOCATION'][f'loc_so_{data_name}']\n",
    "    path_output = config['FILE_LOCATION'][f'loc_{data_name}_with_hash']\n",
    "    df = pd.read_csv(path_data, compression='zip', nrows=10000)\n",
    "\n",
    "    # Add hash_key column to track data changes in each row\n",
    "    df['hash_key'] = df.apply(lambda row: pd.util.hash_pandas_object(\n",
    "        pd.Series(row.to_string())), axis=1)\n",
    "\n",
    "    df.to_csv(path_output)\n",
    "\n",
    "def transform_question_data(config):\n",
    "    \"\"\"\n",
    "\n",
    "    :param config:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    path_question = config['FILE_LOCATION']['loc_question_with_hash']\n",
    "    path_dim_date = config['FILE_LOCATION']['loc_dim_date']\n",
    "    path_fact_question = config['FILE_LOCATION']['loc_fact_question']\n",
    "\n",
    "    df_question = pd.read_csv(path_question, nrows=10000)\n",
    "\n",
    "    # BEGIN: Create dim_date table\n",
    "    # - Get all date columns in question table and exclude time in datetime data\n",
    "    df_date_stg = df_question[['CreationDate', 'ClosedDate', 'DeletionDate']].apply(\n",
    "        lambda date: pd.to_datetime(date).dt.date, axis=1)\n",
    "\n",
    "    # - Combine 3 date columns into one,, remove null and duplicates\n",
    "    sr_date = pd.concat([df_date_stg['CreationDate'], df_date_stg['ClosedDate'], df_date_stg['DeletionDate']], axis=0,\n",
    "                        ignore_index=True).dropna().drop_duplicates().sort_values()\n",
    "\n",
    "    # - Create dim_date dataframe, add relative columns\n",
    "    df_date = pd.DataFrame({'date': sr_date,\n",
    "                            'day': sr_date.apply(lambda d: d.day),\n",
    "                            'weekday': sr_date.apply(lambda d: d.weekday()),\n",
    "                            'month': sr_date.apply(lambda d: d.month),\n",
    "                            'quarter': sr_date.apply(lambda d: int(np.ceil(d.month / 3))),\n",
    "                            'year': sr_date.apply(lambda d: d.year)}).reset_index(drop=True)\n",
    "    df_date.to_csv(path_dim_date)\n",
    "    # END: Create dim_date table\n",
    "\n",
    "    # BEGIN: Transform fact_question table\n",
    "    # - Rename time in datetime columns\n",
    "    df_question.rename(columns={'CreationDate': 'CreationDateTime', 'ClosedDate': 'ClosedDateTime',\n",
    "                                'DeletionDate': 'DeletionDateTime'}, inplace=True)\n",
    "    df_question = pd.concat([df_question, df_date_stg], axis=1)\n",
    "\n",
    "    # - Add status column in fact_question table\n",
    "    df_question['status'] = df_question.apply(lambda row:\n",
    "                                              'Closed' if isinstance(row['ClosedDate'], str) else\n",
    "                                              'Deleted' if isinstance(row['DeletionDate'], str) else\n",
    "                                              'Open', axis=1)\n",
    "    df_question.to_csv(path_fact_question)\n",
    "    # END: Transform fact_question table\n",
    "\n",
    "def transform_question_tag_data(config):\n",
    "    \"\"\"\n",
    "\n",
    "    :param config:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    path_question_tag = config['FILE_LOCATION']['loc_question_tag_with_hash']\n",
    "    path_fact_question_tag = config['FILE_LOCATION']['loc_fact_question_tag']\n",
    "    path_dim_tag = config['FILE_LOCATION']['loc_dim_tag']\n",
    "\n",
    "    df_question_tag = pd.read_csv(path_question_tag, nrows=10000)\n",
    "\n",
    "    # START: Create dim_tag table\n",
    "    # - Get the column Tag in question_tag table\n",
    "    df_tag = df_question_tag['Tag'].drop_duplicates().reset_index(drop=True).reset_index()\n",
    "\n",
    "    # - Rename column for business understanding\n",
    "    df_tag.rename(columns={'index': 'TagID'}, inplace=True)\n",
    "    df_tag.to_csv(path_dim_tag)\n",
    "    # END: Create dim_tag table\n",
    "\n",
    "    # START: Transform fact_question_tag table\n",
    "    df_question_tag = df_question_tag.merge(df_tag, on='Tag')\n",
    "    df_question_tag.drop('Tag', axis=1)\n",
    "    df_question_tag.to_csv(path_fact_question_tag)\n",
    "    # END: Transform fact_question_tag table\n",
    "\n",
    "def push_data_to_s3(config):\n",
    "    \"\"\"\n",
    "\n",
    "    :param config:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    import io\n",
    "    import boto3\n",
    "    import pandas as pd\n",
    "\n",
    "\n",
    "    # Create AWS Credential Session\n",
    "    session = boto3.session.Session(aws_access_key_id=config[\"AWS_CREDENTIAL\"][\"AWS_ACCESS_KEY_ID\"],\n",
    "                                    aws_secret_access_key=config[\"AWS_CREDENTIAL\"][\"AWS_SECRET_ACCESS_KEY\"],\n",
    "                                    aws_session_token=config[\"AWS_CREDENTIAL\"][\"AWS_SESSION_TOKEN\"])\n",
    "    # Put objects into S3 datalake\n",
    "    # Create resource and object\n",
    "    s3 = session.resource('s3')\n",
    "    obj_questions = s3.Object('so-question-dl', 'questions.csv')\n",
    "    obj_question_tags = s3.Object('so-question-dl', 'question_tags.csv')\n",
    "\n",
    "    # Create StringIO to read from DataFrame to CSV files\n",
    "    csv_buffer = io.StringIO()\n",
    "\n",
    "    path_dim_date = config['FILE_LOCATION']['loc_dim_date']\n",
    "    path_dim_tag = config['FILE_LOCATION']['loc_dim_tag']\n",
    "    path_fact_question = config['FILE_LOCATION']['loc_fact_question']\n",
    "    path_fact_question_tag = config['FILE_LOCATION']['loc_fact_question_tag']\n",
    "\n",
    "    df_dim_date = pd.read_csv(path_dim_date, nrows=10000)\n",
    "    df_dim_tag = pd.read_csv(path_dim_tag, nrows=10000)\n",
    "    df_fact_question = pd.read_csv(path_fact_question, nrows=10000)\n",
    "    df_fact_question_tag = pd.read_csv(path_fact_question_tag, nrows=10000)\n",
    "\n",
    "    # Put [dimDate.csv] object into bucket\n",
    "    df_dim_date.to_csv(csv_buffer)\n",
    "    obj_questions.put(Body=csv_buffer.getvalue())\n",
    "    csv_buffer.truncate(0)\n",
    "\n",
    "    # Put [dimTag.csv] object into bucket\n",
    "    df_dim_tag.to_csv(csv_buffer)\n",
    "    obj_questions.put(Body=csv_buffer.getvalue())\n",
    "    csv_buffer.truncate(0)\n",
    "\n",
    "    # Put [factQuestion.csv] object into bucket\n",
    "    df_fact_question.to_csv(csv_buffer)\n",
    "    obj_questions.put(Body=csv_buffer.getvalue())\n",
    "    csv_buffer.truncate(0)\n",
    "\n",
    "    # Put [factQuestionTag.csv] object into bucket\n",
    "    df_fact_question_tag.to_csv(csv_buffer)\n",
    "    obj_questions.put(Body=csv_buffer.getvalue())\n",
    "    csv_buffer.truncate(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = read_config_file()\n",
    "download_data(config, 'question')\n",
    "download_data(config, 'question_tag')\n",
    "\n",
    "add_hash_column(config, 'question')\n",
    "add_hash_column(config, 'question_tag')\n",
    "\n",
    "transform_question_data(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'log_fact_question_tag'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\PAULAN~1\\AppData\\Local\\Temp/ipykernel_10764/33475042.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtransform_question_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtransform_question_tag_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpush_data_to_s3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\PAULAN~1\\AppData\\Local\\Temp/ipykernel_10764/1335711754.py\u001b[0m in \u001b[0;36mtransform_question_tag_data\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[0mpath_question_tag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'FILE_LOCATION'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loc_question_tag_with_hash'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m     \u001b[0mpath_fact_question_tag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'FILE_LOCATION'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'log_fact_question_tag'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m     \u001b[0mpath_dim_tag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'FILE_LOCATION'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loc_dim_tag'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python38\\lib\\configparser.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1252\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1253\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhas_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1254\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1255\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'log_fact_question_tag'"
     ]
    }
   ],
   "source": [
    "transform_question_tag_data(config)\n",
    "\n",
    "push_data_to_s3(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
